<!DOCTYPE HTML>
<html>
   <head>
     <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
      <script type="text/javascript"> 

        // OPEN WEBSOCKET UPON PAGE LOAD
        $(document).ready(function() { 
          // array of arrays with last 10 x,y positions of gaze tracker
          var coords_q = [[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1],[-1,-1]];

          var data = [];    // array of [line_num, timestamp] objects

          var INDEX_URL = "file:///C:/Users/Kathryn Faolin/Documents/thesis/client/index.html";

          if ("WebSocket" in window)

          {
            //alert("WebSocket is supported by your Browser!");
             
            // Let us open a web socket
            var ws = new WebSocket("ws://localhost:9998/Laputa");

            ws.onopen = function()
            {
              // Web Socket is connected, send data using send()
              ws.send("Socket Opened");
              //alert("Message is sent...");

            };

            ws.onmessage = function (evt) 
            { 
              var received_msg = evt.data;
              // console.log(received_msg);          // uncomment to log all coordinates

              var tokens = received_msg.split('|');

              if (tokens[0] === 'during') {

                // get normalized gaze position
                var tobii_x = tokens[1];
                var tobii_y = tokens[2];
                var x = tobii_x + window.screenLeft + (window.outerWidth - window.innerWidth);
                var y = tobii_y + window.screenTop - (window.outerHeight - window.innerHeight);

                // smoothing -- compute stabilized x and y coords
                // use coords_q as queue sliding over past 10 x,y positions
                // mean of these is our current position1
                var x_sum = 0.0;
                var y_sum = 0.0;
                var avg_denom = 0.0; // needed b/c of initial cases where coords_q not filled fully
                coords_q.push([x,y]);
                coords_q.shift();
                for(var i = 0; i < coords_q.length; i++) {
                  if (coords_q[i][0] !== -1) {
                    x_sum += parseFloat(coords_q[i][0]);
                    y_sum += parseFloat(coords_q[i][1]);
                    avg_denom += 1;
                  }
                }
                x = x_sum / avg_denom;
                y = y_sum / avg_denom;

                // add an offset to deal with slight innacuracy (one line' worth)
                y += 28;

                // draw dot at current gaze position    DO NOT DELETE!!!! -- uncomment whenever you need tracer
                
                var dot_color = 'green';
                var dot_size = '5px';
                $("body").append(
                  $('<div></div>')
                     .css('position', 'absolute')
                     .css('top', y + 'px')
                     .css('left', x + 'px')
                     .css('width', dot_size)
                     .css('height', dot_size)
                     .css('background-color', dot_color)
                );
                
                

                // highlight word at current gaze position
                $(function () {


                  /////////////////////////////////////////////////////////////////////////////////
                  // HIGHLIGHTING MECHANISM
                  // inspired by: https://stackoverflow.com/questions/2456442/how-can-i-highlight-the-line-of-text-that-is-closest-to-the-mouse/2456631#2456631
                  // and hence: http://jsbin.com/avuku/15/edit?html,js,output
                  /////////////////////////////////////////////////////////////////////////////////

                  var lines = document.getElementById("wrappingText").getClientRects();  // declared globally instead
                  var highlighter = document.getElementById("highlighter");

                  // all the action
                  for (var i=0, max = lines.length; i < max; i++)
                  {
                      if (y > lines[i].top && y < lines[i].bottom)
                      {
                        data.push([i, Date.now()]) // record line seen and timestamp for when

                        var centerPos = lines[i].top;
                        var bottomPos = lines[i].bottom;
                        if (lines[i+1] !== null && lines[i+1] !== undefined) {
                          bottomPos = lines[i+1].top;  
                        }                                                        
                        var hlightHeight = bottomPos - centerPos;
                        var topPos = centerPos - hlightHeight;
                        if (lines[i-1] !== null && lines[i-1] !== undefined) {
                          topPos = lines[i-1].top;  
                        } 
                        /* // other way for top and bottom pos
                        var topPos = centerPos - hlightHeight;
                        var bottomPos = centerPos + hlightHeight;
                        */

                        // height of each highlighter is same
                        $("#hlighterCenter, .hlighterOuter").css("height", hlightHeight);

                        // positions of top bottom and center
                        $("#hlighterTop").css("top", topPos);                                                   
                        $("#hlighterCenter").css("top", centerPos);
                        $("#hlighterBottom").css("top", bottomPos);                           
                        break;
                      } 
                  }

                });       
              }
            };

            ws.onclose = function()
            { 
              // websocket is closed.
              // alert("Connection is closed..."); 
            };

            window.onbeforeunload = function(event) {
              // Close the connection, if open.
              if (ws.readyState === WebSocket.OPEN) {

                // TODO: conceptual thing - why was doc.getElembyid not giving
                // correct result unless you toggled?
                var infoToSend = {
                  article: '4',
                  user: '1',
                  hlight: $("#hlighterCenter").css("visibility"),
                  data: data
                };

                ws.send(JSON.stringify(infoToSend));
                ws.close();
              };
            }
          
          }
          else
          {
            // The browser doesn't support WebSocket
            alert("WebSocket NOT supported by your Browser!");
          }


        });

      </script>


      <style type="text/css">
        body {
          display: flex;
          flex-flow: row nowrap;
          justify-content: space-between;
        }
        div 
        {
          font-size: 16px;
          font-family: 'Georgia';
          line-height: 28px;
        }
        .hlighter {
          position:absolute;
          width:100%;
          z-index: -1;
        }
        /* for box shadow: https://stackoverflow.com/questions/45143916/dim-entire-screen-except-a-fixed-area */
        /* this box shadow is doing something to the opacity of the top highlighter div, but no issue yet */
        #hlighterCenter {
          background-color:white;
          box-shadow: 0 0 0 100vmax rgba(0,0,0,.18);
        }
        .hlighterOuter {
          background-color:khaki;
          opacity: 0.5;    
        }
        #wrappingText {
          display: inline;
        } 
        #container {
          border-left: 1px solid black;
          padding-left: 10px;
        }
        #sse {
          width: 80px;
          display: flex;
        }
        /* THIS IS WHERE YOU WILL TOGGLE HLIGHTER FROM */
        #hlighterTop, #hlighterCenter, #hlighterBottom {
          visibility: hidden;
        }
      </style>
    
   </head>
   <body>
      <div id="sse">
      </div>
      <div id="container">
        <div class="hlighter hlighterOuter" id="hlighterTop"></div>
        <div class="hlighter" id="hlighterCenter"></div>
        <div class="hlighter hlighterOuter" id="hlighterBottom"></div>
        <div id="wrappingText">
          THEY'RE ALWAYS LISTENING. They’re on the internet. But what happens when digital assistants like Alexa go rogue? Could they share our private conversations without our consent? Privacy advocates have long warned this could happen, and now it has. A woman in Portland, Ore., told KIRO7, a television news station in Washington, that her Amazon Echo device had recorded a conversation then shared it with one of her husband’s employees in Seattle. Skeptics were quick to say we told you so, as the news rocketed through the connected world.
          </br></br>
          Now, Amazon says it knows what happened: As the woman, identified only as Danielle, chatted away with her husband, the device’s virtual assistant, Alexa, mistakenly heard a series of requests and commands to send the recording as a voice message to one of the husband’s employees. “Echo woke up due to a word in background conversation sounding like ‘Alexa,’” Amazon said in a statement. “Then, the subsequent conversation was heard as a ‘send message’ request. At which point, Alexa said out loud ‘To whom?’ At which point, the background conversation was interpreted as a name in the customer’s contact list. Alexa then asked out loud, ‘[contact name], right?’ Alexa then interpreted background conversation as ‘right’. As unlikely as this string of events is, we are evaluating options to make this case even less likely.” In a follow-up interview, though, Danielle told KIRO7 that the Echo that shared her conversation was right next to her at the time with the volume set to seven out of 10. It never requested her permission to send the audio, she said. The family had several Echoes in their home, using them to control the heat, lights and security system. But, two weeks ago, Danielle’s husband received a call from the employee in Seattle, who reported receiving audio of their conversation. “At first, my husband was like, ‘No, you didn’t,’” Danielle told KIRO7. “And he’s like, ‘You sat there talking about hardwood floors.’ And we said, ‘Oh gosh, you really did!’” The family disconnected the devices and contacted Amazon, prompting an investigation. Now, Danielle is asking for a refund. “I’m never plugging that device in again,” she told KIRO7. “I can’t trust it.”
          </br></br>
          If you own an Echo and are concerned about what it might be recording, an Amazon help page explains that you can review, listen and delete the audio and other interactions in the settings menu. The news was met with a mix of alarm and humor on social media. Amazon’s main home assistant devices — the Echo, Echo Plus and Echo Dot — are each equipped with seven microphones and noise-canceling technology. Amazon and Google are the leading sellers of such devices. This is not the first report of an Echo mishearing commands, with unusual results. Amazon offered a similar explanation in March after several users reported hearing Alexa laugh at random times. The assistant, the company said, had “in rare circumstances” mistakenly heard “Alexa, laugh.” As a result, Amazon changed the phrase for that command to “Alexa, can you laugh?” and had the device verbally acknowledge such requests. This month, researchers at the University of California, Berkeley, said in a published paper that they had proved that the technology could be exploited, too. The researchers said that they were able to hide commands in recordings of music or spoken text that went unnoticed by humans but were understood by personal assistants such as Apple’s Siri, Google’s Assistant and Amazon’s Alexa. Questions like the above are prompting some prognosticators to question why we're using these devices at all. Indeed, these days, you can find virtual assistants like Amazon’s Alexa or Google’s Assistant in all sorts of things, from smart speakers and smartphones to washing machines and bathroom mirrors. The challenge isn’t finding these digitized helpers, it is finding people who use them to do much more than they could with the old clock/radio in the bedroom. A management consulting firm recently looked at heavy users of virtual assistants, defined as people who use one more than three times a day. The firm, called Activate, found that the majority of these users turned to virtual assistants to play music, get the weather, set a timer or ask questions.
        </div>
      </div>
   </body>
</html>